{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following notebook is to run an experiment for Shot Boundary Detection\n",
    "\n",
    "Based of off ideas presented in https://arxiv.org/pdf/1705.08214.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python files imported\n",
    "\n",
    "- model_zoo.py: Contains all the models\n",
    "- training.py: Contains training and validation code\n",
    "- data.py: Contains all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo import sbd_detector_1, sbd_detector_2\n",
    "from training import train_step, val_step, train\n",
    "from data import get_random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set seeds and get GPU details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device - cpu\n"
     ]
    }
   ],
   "source": [
    "seed = 8964\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Current Device - %s\" % device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Device Count - %s\" % torch.cuda.device_count())\n",
    "    print(\"CUDA Device Name - %s\" % torch.cuda.get_device_name())\n",
    "    print(\"CUDA Device Memory - %0.2f GB\"%(float(torch.cuda.get_device_properties(0).total_memory)/1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the data\n",
    "\n",
    "Options are get_random_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 2 # No of batches\n",
    "batch_size = 128\n",
    "T = 10 # Time: Length of base sequence passed\n",
    "N = 3 # Additional frames to be included in the sequence\n",
    "\n",
    "random_dataloader = get_random_data(n_batches, batch_size, T, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the model\n",
    "\n",
    "Options are sbd_detector_1, sbd_detector_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SBD_Detector_1 works for only base length frame sequence T\n",
    "- SBD_Detector_2 works for variable length sequence (T+N). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: sbd_detector_2\n",
      "Input Size: torch.Size([128, 3, 13, 64, 64])\n",
      "After Layer 1: torch.Size([128, 16, 11, 30, 30])\n",
      "After Layer 2: torch.Size([128, 24, 9, 14, 14])\n",
      "After Layer 3: torch.Size([128, 32, 7, 6, 6])\n",
      "After Layer 4: torch.Size([128, 12, 7, 1, 1])\n",
      "After Layer 5: torch.Size([128, 2, 4, 1, 1])\n",
      "Output Size:torch.Size([128, 2, 4, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "model = sbd_detector_2()\n",
    "model.summarize(random_dataloader[0][0])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment configuration\n",
    "\n",
    "- Loss Function\n",
    "- Optimizer\n",
    "- Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.0001, momentum=0, nesterov=False)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.97)\n",
    "\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch : 0\n",
      "Train Step\n",
      "batch: 0, loss: 0.7134177088737488, correct : 0\n",
      "batch: 1, loss: 0.7134486436843872, correct : 0\n",
      "Total loss : 1.426866352558136\n",
      "Total Acc : 0.0\n",
      "Val Step\n",
      "batch: 0, loss: 0.7133011817932129, correct : 0\n",
      "batch: 1, loss: 0.7133904695510864, correct : 0\n",
      "Total loss : 1.4266916513442993\n",
      "Total Acc : 0.0\n",
      "Running epoch : 1\n",
      "Train Step\n",
      "batch: 0, loss: 0.7133011817932129, correct : 0\n",
      "batch: 1, loss: 0.7133321762084961, correct : 0\n",
      "Total loss : 1.426633358001709\n",
      "Total Acc : 0.0\n",
      "Val Step\n",
      "batch: 0, loss: 0.7131849527359009, correct : 0\n",
      "batch: 1, loss: 0.7132735252380371, correct : 0\n",
      "Total loss : 1.426458477973938\n",
      "Total Acc : 0.0\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs, model, optimizer, scheduler, criterion, random_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(num_epochs, model, optimizer, scheduler, criterion):\n",
    "    \n",
    "    epoch = 0\n",
    "    \n",
    "    while epoch < num_epochs:\n",
    "        print(f'Running epoch : {epoch}')\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                \n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode        \n",
    "        \n",
    "            running_loss = 0.0\n",
    "            print(f'Running phase : {phase}')\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i,_ in enumerate(range(2)):\n",
    "                samples, targets = batch\n",
    "                samples = samples.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    preds = model(samples)\n",
    "                    loss = criterion(preds, targets.float())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                print(f'batch: {i}, loss: {loss}')\n",
    "                running_loss += loss.item()\n",
    "        \n",
    "            print(f'Total loss : {running_loss}')\n",
    "            \n",
    "        epoch += 1\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
